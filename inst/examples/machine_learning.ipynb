{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7878bc",
   "metadata": {},
   "source": [
    "#### Examples for machine learning algorithms by dsldPy\n",
    "\n",
    "The goal is for users to train models with a simple, intuitive interface and also understand effects on fairness-utility tradeoffs based on hyperparamater selection. Examples are shown on training/testing sets with cross validation approaches.\n",
    "\n",
    "1) regression examples using dsldPyFairML and dsldPyQeFairML\n",
    "2) classification examples using dsldPyFairML and dsldPyQeFairML\n",
    "3) k-fold cross validation to choose best hyperparameters for fairness utility tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da083337",
   "metadata": {},
   "outputs": [],
   "source": [
    "## requires R and the dsld (R) package installed\n",
    "# !pip install dsldPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd05554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from dsldPy import (\n",
    "# data reading and preprocessing\n",
    "preprocess_data, read_data,\n",
    "\n",
    "# fairML wrappers\n",
    "dsldPyFrrm, dsldPyFgrrm, dsldPyNclm, dsldPyZlm, dsldPyZlrm, dsldPyFairML_Summary, dsldPyFairML_Predict,\n",
    "\n",
    "# qeFairML wrappers\n",
    "dsldPyQeFairKNN, dsldPyQeFairRF, dsldPyQeFairRidgeLin, dsldPyQeFairRidgeLog, dsldPyQeFairML_Predict,\n",
    "\n",
    "dsldPyFairUtils\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### regression example --- frrm(), nclm(), zlm(), qeFairKNN(), qeFairRF(), qeFairRidgeLin()\n",
    "\n",
    "### read and preprocess data\n",
    "\n",
    "### data preprocessing\n",
    "\n",
    "### all dsldPy functions require a R data frame object as input (NOT pandas dataframe)\n",
    "### the preprocessing is done by the function preprocess_data\n",
    "### user needs to manually provide the categorical and numerical features (list)\n",
    "### the function preprocess_data returns a R data.frame object -> required input for the dsldPy functions\n",
    "\n",
    "# test and train split\n",
    "#### REPLACE WITH YOUR PATH TO svcensus.RData\n",
    "# df = read_data(\"\") \n",
    "test_df, train_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "test_y = test_df['wageinc']\n",
    "test_df = test_df.drop(columns=['wageinc'])\n",
    "\n",
    "# preprocess data\n",
    "cat_features_train = ['educ', 'occ', 'gender']\n",
    "num_features_train = ['age', 'wageinc', 'wkswrkd']\n",
    "svcensus_train = preprocess_data(train_df, cat_features_train, num_features_train)\n",
    "\n",
    "cat_features_test = ['educ', 'occ', 'gender']\n",
    "num_features_test = ['age', 'wkswrkd']\n",
    "svcensus_test = preprocess_data(test_df, cat_features_test, num_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08603d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using dsldPyFairML() function\n",
    "\n",
    "### model training --- frrm() \n",
    "### unfairness = 0.05 // can also try different values for unfairness\n",
    "a = dsldPyFrrm(data=svcensus_train, yName='wageinc', sName='gender',unfairness= 0.05, definition = \"sp-komiyama\", lamda = 0, save = False)\n",
    "\n",
    "# print train accuracy and correlations\n",
    "print(f\"train predictions: {a['train_predictions']}\")\n",
    "print(f\"train accuracy: {a['train_accuracy']}\")\n",
    "print(f\"train correlations: {a['train_correlations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict() on test data\n",
    "a_preds = dsldPyFairML_Predict(a, svcensus_test)\n",
    "\n",
    "# print test predictions and correlations\n",
    "print(f\"test predictions: {a_preds['test_predictions']}\")\n",
    "print(f\"test correlations: {a_preds['test_correlations']}\")\n",
    "\n",
    "# manuallycompute test accuracy (MAPE)\n",
    "test_accuracy = mean_absolute_error(test_y, a_preds['test_predictions'])\n",
    "print(f\"test accuracy: {test_accuracy}\")\n",
    "\n",
    "### the same can be done for other models --- nclm(), zlm() with dsldPyFairML_Predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using dsldPyQeFairML() functions \n",
    "\n",
    "### model training --- dsldQeFairRF() \n",
    "### deweightPars = {'educ': 0.2, 'occ': 0.05} // try different values for proxies\n",
    "deweightPars = {'educ': 0.2, 'occ': 0.05}\n",
    "\n",
    "a = dsldPyQeFairRF(data=svcensus_train, yName='wageinc', sNames='gender', deweightPars=deweightPars)\n",
    "\n",
    "# print train accuracy and correlations\n",
    "print(f\"train predictions: {a['train_predictions']}\")\n",
    "print(f\"train accuracy: {a['train_accuracy']}\")\n",
    "print(f\"train correlations: {a['train_correlations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63aaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict on test data\n",
    "a_preds = dsldPyQeFairML_Predict(a, svcensus_test)\n",
    "\n",
    "# print test predictions and correlations\n",
    "print(f\"test predictions: {a_preds['test_predictions']}\")\n",
    "print(f\"test correlations: {a_preds['test_correlations']}\")\n",
    "\n",
    "# manually compute test accuracy (MAPE)\n",
    "test_accuracy = mean_absolute_error(test_y, a_preds['test_predictions'])\n",
    "print(f\"test accuracy: {test_accuracy}\")\n",
    "\n",
    "### the same can be done for other models --- qeFairKNN(), qeFairRidgeLin() with dsldPyQeFairML_Predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "### classification examples --- fgrrm(), zlrm(), qeFairKNN(), qeFairRF(), qeFairRidgeLog()\n",
    "\n",
    "### read and preprocess data\n",
    "\n",
    "# test and train split\n",
    "#### REPLACE WITH YOUR PATH TO compas1.RData\n",
    "# df = read_data(\"\")\n",
    "test_df, train_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "test_y = test_df['two_year_recid']\n",
    "test_y = test_df['two_year_recid'].map({'Yes': 1, 'No': 0})            # convert to binary\n",
    "test_df = test_df.drop(columns=['two_year_recid'])\n",
    "\n",
    "# preprocess data\n",
    "cat_features = ['sex', 'race', 'two_year_recid']\n",
    "num_features = [\"age\", \"juv_fel_count\",\"decile_score\",\"juv_misd_count\",\"juv_other_count\",\"priors_count\",\"c_jail_in\",\"c_jail_out\",\"c_offense_date\",\"screening_date\",\"in_custody\",\"out_custody\"]\n",
    "compas1_train = preprocess_data(train_df, cat_features_train, num_features_train)\n",
    "\n",
    "cat_features = ['sex', 'race']\n",
    "num_features = [\"age\", \"juv_fel_count\",\"decile_score\",\"juv_misd_count\",\"juv_other_count\",\"priors_count\",\"c_jail_in\",\"c_jail_out\",\"c_offense_date\",\"screening_date\",\"in_custody\",\"out_custody\"]\n",
    "compas1_test = preprocess_data(test_df, cat_features_test, num_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d728fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using dsldPyFairML() functions \n",
    "\n",
    "### model training --- fgrrm() \n",
    "### unfairness = 0.1 // try different values for unfairness\n",
    "a = dsldPyFgrrm(data=compas1_train, yName='two_year_recid', sName='race', unfairness=0.1, definition = \"sp-komiyama\", family = \"binomial\", lamda = 0, save = False, yesYVal = \"Yes\")\n",
    "\n",
    "# print train accuracy and correlations\n",
    "print(f\"train predictions: {a['train_predictions']}\")             # returns prob = Yes\n",
    "print(f\"train accuracy (misclassification rate): {a['train_accuracy']}\")\n",
    "print(f\"train correlations: {a['train_correlations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict() on test set\n",
    "a_preds = dsldPyFairML_Predict(a, compas1_test)\n",
    "\n",
    "# print test predictions and correlations\n",
    "print(f\"test predictions: {a_preds['test_predictions']}\") # returns prob = Yes\n",
    "print(f\"test correlations: {a_preds['test_correlations']}\")\n",
    "\n",
    "# manually compute test accuracy (MAPE)\n",
    "y_pred = [int(round(x)) for x in a_preds['test_predictions']]\n",
    "test_accuracy = accuracy_score(test_y, y_pred)\n",
    "misclass_rate = 1 - test_accuracy\n",
    "\n",
    "# print train accuracy and correlations\n",
    "print(f\"test accuracy (misclassification rate): {misclass_rate}\")\n",
    "\n",
    "### the same can be done for other models --- zlrm() with dsldPyFairML_Predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using dsldPyQeFairML() functions \n",
    "\n",
    "### model training --- dsldQeFairKNN() \n",
    "### deweightPars = {'decile_score': 0.2, 'priors_count': 0.5} // try different values for deweightPars\n",
    "deweightPars = {'decile_score': 0.2, 'priors_count': 0.5}\n",
    "\n",
    "a = dsldPyQeFairKNN(data=compas1_train, yName='two_year_recid',sNames= 'race', deweightPars=deweightPars, k = 10, scaleX = True, yesYVal = \"Yes\")\n",
    "\n",
    "# print train accuracy and correlations\n",
    "# in the case of classification, the train_predictions returns both predClasses and prob = Yes\n",
    "print(f\"train predictions: {a['train_predictions']}\")     \n",
    "print(f\"train accuracy: {a['train_accuracy']}\")\n",
    "print(f\"train correlations: {a['train_correlations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict() on test set\n",
    "a_preds = dsldPyQeFairML_Predict(a, compas1_test)\n",
    "\n",
    "# print test predictions and correlations\n",
    "print(f\"test predictions: {a_preds['test_predictions']}\")\n",
    "print(f\"test correlations: {a_preds['test_correlations']}\")\n",
    "\n",
    "# compute test accuracy\n",
    "y_pred = [int(round(x)) for x in list(a_preds['test_predictions'][1])]\n",
    "test_accuracy = accuracy_score(test_y, y_pred)\n",
    "misclass_rate = 1 - test_accuracy\n",
    "\n",
    "# print train accuracy and correlations\n",
    "print(f\"test accuracy (misclassification rate): {misclass_rate}\")\n",
    "\n",
    "### the same can be done for other models --- dsldQeFairRF(), dsldQeFairRidgeLog() with dsldPyQeFairML_Predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398cbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### k-fold cross validation to find best model based on fairness and accuracy\n",
    "dsldPyFairUtils(data=svcensus_train, yName='wageinc', sName='gender', dsldFTNname = \"dsldFrrm\", unfairness = [0.01, 0.05, 0.1, 0.2, 0.8], k_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsldPyFairUtils(data = svcensus_train, yName = 'wageinc', sName = 'gender', dsldFTNname = \"dsldQeFairKNN\", deweightPars = {'occ': [0.9 ,0.8 ,0.5 ,0.3 ,0.1 ,0.05 ,0.01]}, k_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04839f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
